Metadata-Version: 2.4
Name: slurm-gzip
Version: 1.0.0
Summary: A Python program that scans directories for files with specific suffixes and generates task files for gzip compression operations with Slurm integration
Author-email: Rauf Salamzade <salamzader@gmail.com>
Maintainer-email: Rauf Salamzade <salamzader@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/raufs/slurm_gzip
Project-URL: Repository, https://github.com/raufs/slurm_gzip.git
Project-URL: Documentation, https://github.com/raufs/slurm_gzip#readme
Project-URL: Issues, https://github.com/raufs/slurm_gzip/issues
Project-URL: Changelog, https://github.com/raufs/slurm_gzip/releases
Keywords: slurm,gzip,compression,batch-processing,hpc,cluster
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: System Administrators
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: POSIX :: Linux
Classifier: Operating System :: Unix
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: System :: Archiving :: Compression
Classifier: Topic :: System :: Distributed Computing
Classifier: Topic :: Utilities
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: test
Requires-Dist: pytest>=7.0.0; extra == "test"
Requires-Dist: pytest-cov>=4.0.0; extra == "test"
Dynamic: license-file

# Slurm Gzip Task Generator

A Python program that scans directories for files with specific suffixes and generates task files for gzip compression operations. It can also generate and optionally auto-submit Slurm batch scripts.

## Features

- **File Discovery**: Recursively scan directories for files with specified suffixes
- **Task File Generation**: Create command files ready for parallel execution
- **Slurm Integration**: Generate Slurm batch scripts with customizable parameters
- **Auto-submission**: Option to automatically submit jobs to Slurm (with confirmation)
- **Flexible Configuration**: Customize output files, Slurm parameters, and execution options

## Requirements

- Python 3.6+
- Access to a Slurm cluster (for Slurm functionality)
- Standard Unix tools (gzip, parallel, etc.)

## Installation

1. Clone or download the repository
2. Make the script executable:
   ```bash
   chmod +x slurm_gzip.py
   ```

## Usage

### Basic Usage

Scan current directory for `.txt` and `.log` files:
```bash
python slurm_gzip.py -s .txt .log
```

Scan specific directory:
```bash
python slurm_gzip.py -d /path/to/files -s .txt .log
```

Custom output file:
```bash
python slurm_gzip.py -s .txt .log -o my_tasks.cmds
```

### Slurm Integration

Generate Slurm batch script:
```bash
python slurm_gzip.py -s .txt .log --slurm
```

Customize Slurm parameters:
```bash
python slurm_gzip.py -s .txt .log --slurm \
  --partition=short \
  --ntasks=4 \
  --mem=8G \
  --time=01:00:00
```

Auto-submit to Slurm (with confirmation):
```bash
python slurm_gzip.py -s .txt .log --slurm --auto-run
```

### Command Line Options

```
-d, --directory DIR     Directory to scan (default: current directory)
-s, --suffixes SUFFIX   File suffixes to look for (required)
-o, --output FILE       Output task file name (default: gzip.cmds)
--slurm                 Generate Slurm batch script
--auto-run             Automatically submit to Slurm (requires --slurm)

Slurm Parameters:
--partition PART        Slurm partition
--nodes N              Number of nodes
--ntasks N             Number of tasks
--cpus-per-task N      CPUs per task
--mem MEM              Memory per node
--time TIME            Time limit (HH:MM:SS)
--output-log FILE      Output log file
--error-log FILE       Error log file
```

## Output Files

### Task File (default: `gzip.cmds`)
Contains one gzip command per line, ready for parallel execution:
```bash
# Example gzip.cmds
gzip '/path/to/file1.txt'
gzip '/path/to/file2.log'
gzip '/path/to/file3.txt'
```

### Slurm Script (default: `gzip_slurm.sh`)
Bash script with Slurm directives and execution logic.

## Execution Methods

### Local Execution
```bash
# Using GNU parallel
parallel < gzip.cmds

# Using xargs
xargs -P $(nproc) -a gzip.cmds

# Individual execution
bash gzip.cmds
```

### Slurm Execution
```bash
# Submit batch job
sbatch gzip_slurm.sh

# Interactive execution
srun --multi-prog gzip.cmds
```

## Examples

### Example 1: Basic File Compression
```bash
# Find and compress all .txt files in current directory
python slurm_gzip.py -s .txt

# Review generated task file
cat gzip.cmds

# Execute locally
parallel < gzip.cmds
```

### Example 2: Slurm Batch Job
```bash
# Generate Slurm script for large dataset
python slurm_gzip.py -d /data/large_files -s .csv .tsv --slurm \
  --partition=long \
  --ntasks=16 \
  --mem=32G \
  --time=04:00:00

# Submit job
sbatch gzip_slurm.sh
```

### Example 3: Auto-submission with Confirmation
```bash
# Generate and auto-submit (will prompt for confirmation)
python slurm_gzip.py -d /data/files -s .log --slurm --auto-run
```

## Safety Features

- **Confirmation Required**: Auto-submission always prompts for user confirmation
- **File Review**: Generated files are displayed for review before execution
- **Skip Compressed**: Already compressed (.gz) files are automatically skipped
- **Error Handling**: Comprehensive error checking and informative messages

## Tips

1. **Always review** generated task files before execution
2. **Test locally** with a small subset before running on Slurm
3. **Use appropriate** Slurm parameters for your cluster
4. **Monitor jobs** using `squeue` and `sacct` commands
5. **Check logs** for any compression errors

## Troubleshooting

### Common Issues

- **No files found**: Check directory path and suffix specifications
- **Permission denied**: Ensure script is executable and you have read access to target directory
- **Slurm not found**: Verify you're on a Slurm cluster and `sbatch` is available
- **Compression errors**: Check file permissions and disk space

### Debug Mode
Add `-v` or `--verbose` for more detailed output (if implemented).

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contributing

Contributions are welcome! Please feel free to submit issues, feature requests, or pull requests.
